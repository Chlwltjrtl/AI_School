2주차 질문요약

왜 경사 하강법을 사용하냐?
->> 답변
gradient descent , ascent ? 를 정의 할수 있느냐
descent 줄이는거
ascent 늘리는거 
선정순서
1. 모델
2. loss function
3. Optimization || 중 gradient descent 를 사용한다 


----------
saddle points - > 뉴럴네트워크에서 
Select a search direction si

미분한것은 그함수값에 x 에 증가하는 방향을 가르킨다. (백터에서 방향 * ) 
Steepest Gradient Descent

error를 전체에대한 것으로 볼꺼냐, 한개에 대한 sample error 를 볼거냐 
==> batch: 전체 -> 우리가 logistic regression 할때처럼 || Stochastic 각각의 셈플

mini-batch  가장많이 사용 , 각각의 장점을 타협해서 사용
p.12 -> 그래프비교 
mini-batch 가 계산상 이윤이 있음 , local 옥티븜? : 다른 값을 찾아갈라함
Stochastic 방법은 그후에 수정 가능

Shuffle data D : 매 epoch 들어가기전 shuffle 하는것

gradient = 1차미분
==========
hessian = 2차미분
속도'  = 가속도
gradeint' =  얼마나 빨리 gradeint 하느냐 (hessain 안에 개념이 들어가잇음)
linear regression 에 적용하면 한방에 찾음 !-> Newton's

단점이  어디서 시작하냐 에 따라 gradient 값이 global 에서 local 로 빠질 수있음 
그래서 딥러닝을하면 많이 해봐라 

---------------
두더지 ?
K-means - 저번시간에 안한 베이시스 사용
unsuperviesed learning , 답이없는상태에서 , 비지도학습
데이터 마이닝에서 사용
n개의 데이터를 주었을때 divied?
그룹을 나눌때 대표값을 지정하여 , 셈플들의 평균이라 생각


Prototype uk = k 번째 clustter 에 center 값이다 -> 숙제?
 rnk ∈ {0, 1} 속하냐 안속하냐 
‘1-of-K coding scheme 사용 - > logistic regression 할때 사용했던거

	loss function정의 p.4 
data points to clusters 
데이터를 특정 클러스터에 지정해야됨
한점이 여러 class 에 속할수 없다.
assignment 해야됨
각 평균값이 뭐냐 
x 가 맞는 클러스터에 해당되어야 하고, 평균에 가까워야한다.

	k-means 알고리즘
1. 랜덤값으로 초기값을 한다. 
Choose some initial values for the uk
2. r값 지정 , 각각의 셈플을 할당한다.     (expectation)         -> 어사이먼트 단계
Minimize J w.r.t. the {rnk}, keeping the {uk} fixed
-> random 으로 채웠으니 별로 좋지않은 프로토타입이다.
(expectation) -> 추론
3. uk로 미분? (maximization)
Minimize J w.r.t. the {uk}, keeping the {rnk} fixed
	sum 을 최소화시키는게 뭐냐?


사진 p.8
1. rnk 설정
2. 클러스팅 - > 안좋은 프로토타입이다.
3. 프로토타입을 업데이트 -> 전에 할당된 점들의 평균으로 감
4. 색을 지우고 다시 assign? 어사인
5. 다시 프로토타입을 업데이트
6. 반복~
9. 업데이트 가 이루어지는것이 0 에 가까워 지면 끝

p.9 -> EM알고리즘을 보면 계속줄어드는지 알수있음

k-means 의 단점
1. 초기값을 잘못 잡으면 모든점들이 어사인이 잘못되서 극단적으로 , 우연히 같은점으로 나온다면 랜덤으로 정리됨 -> 랜덤으로 초기값을 줄경우
2. 내가가지고 있는 데이터 셈플중 랜덤으로 k 개를 뽑아 프로토타입인 마냥 시작 
3. 다음에

Dissimilarity measure

유클리디안 거리에 해당하는거리를 상황에 맞춰 사용하면된다?

---
k-means 예제
Image segmentation
Lossy data compression
------------
Linear Basis Function Models

리뉴얼 레그렉션, y = w^T * x  , x 에대한 선형식, w 에 대한 선형식 
무엇을 변수를 보냐에 따라 공간이 달라짐

x 차원 기준 , 선형문제점은? -> sigmoid 처럼생긴 곡선을 처리 불가능
하지만 곡선으로 바꿀수 있는게 있다. -> x 의 차수를 증가시키면된다.

입력 x 의 form 을 바꾼것만으로도 비선형으로 바꿀수 있다. 
-> w 에대한것은 선형이지만 x 는 1차가아니다.  == 선형 함수의 장점을 가지고있다. 해석이쉽다.
이걸 입력 x를 Basis function 을 통과시켜서 바꾼것 이라고함

하지만 Linear을 사용하면 별 소용이없다. 그래서 비선형함수를 사용해야됨

Rbf - 정규 분포 에 데이터가 존재하는 지 알면 RBF 사용해도된다?
데이터의 특성을 스스로 학습 - > k-means

Logistic 에 사용하면 비선형으로 ~
=========


